{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Lab6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FintZZPtbu6"
      },
      "source": [
        "<a \n",
        "href=\"https://colab.research.google.com/github/wingated/cs474_labs_f2019/blob/master/DL_Lab6.ipynb\"\n",
        "  target=\"_parent\">\n",
        "  <img\n",
        "    src=\"https://colab.research.google.com/assets/colab-badge.svg\"\n",
        "    alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cksgAH12XRjV"
      },
      "source": [
        "# Lab 6: Sequence-to-sequence models\n",
        "\n",
        "### Description:\n",
        "For this lab, you will code up the [char-rnn model of Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). This is a recurrent neural network that is trained probabilistically on sequences of characters, and that can then be used to sample new sequences that are like the original.\n",
        "\n",
        "This lab will help you develop several new skills, as well as understand some best practices needed for building large models. In addition, we'll be able to create networks that generate neat text!\n",
        "\n",
        "### Deliverable:\n",
        "- Fill in the code for the RNN (using PyTorch's built-in GRU).\n",
        "- Fill in the training loop\n",
        "- Fill in the evaluation loop. In this loop, rather than using a validation set, you will sample text from the RNN.\n",
        "- Implement your own GRU cell.\n",
        "- Train your RNN on a new domain of text (Star Wars, political speeches, etc. - have fun!)\n",
        "\n",
        "### Grading Standards:\n",
        "- 20% Implementation the RNN\n",
        "- 20% Implementation training loop\n",
        "- 20% Implementation of evaluation loop\n",
        "- 20% Implementation of your own GRU cell\n",
        "- 20% Training of your RNN on a domain of your choice\n",
        "\n",
        "### Tips:\n",
        "- Read through all the helper functions, run them, and make sure you understand what they are doing\n",
        "- At each stage, ask yourself: What should the dimensions of this tensor be? Should its data type be float or int? (int is called `long` in PyTorch)\n",
        "- Don't apply a softmax inside the RNN if you are using an nn.CrossEntropyLoss (this module already applies a softmax to its input).\n",
        "\n",
        "### Example Output:\n",
        "An example of my final samples are shown below (more detail in the\n",
        "final section of this writeup), after 150 passes through the data.\n",
        "Please generate about 15 samples for each dataset.\n",
        "\n",
        "<code>\n",
        "And ifte thin forgision forward thene over up to a fear not your\n",
        "And freitions, which is great God. Behold these are the loss sub\n",
        "And ache with the Lord hath bloes, which was done to the holy Gr\n",
        "And appeicis arm vinimonahites strong in name, to doth piseling \n",
        "And miniquithers these words, he commanded order not; neither sa\n",
        "And min for many would happine even to the earth, to said unto m\n",
        "And mie first be traditions? Behold, you, because it was a sound\n",
        "And from tike ended the Lamanites had administered, and I say bi\n",
        "</code>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2i_QpSsWG4c"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 0: Readings, data loading, and high level training\n",
        "\n",
        "---\n",
        "\n",
        "There is a tutorial here that will help build out scaffolding code, and get an understanding of using sequences in pytorch.\n",
        "\n",
        "* Read the following\n",
        "\n",
        "> * [Pytorch sequence-to-sequence tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) (Take note that you will not be implementing the encoder part of this tutorial.)\n",
        "* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7bdZWxvJrsx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "62532a19-4a88-4533-e6e5-cfd893cb0d49"
      },
      "source": [
        "! wget -O ./text_files.tar.gz 'https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz' \n",
        "! tar -xzf text_files.tar.gz\n",
        "! pip install unidecode\n",
        "! pip install torch\n",
        "\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        " \n",
        "import pdb\n",
        " \n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "file = unidecode.unidecode(open('./text_files/lotr.txt').read())\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-10 03:15:33--  https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz\n",
            "Resolving piazza.com (piazza.com)... 54.205.50.50, 3.212.158.118, 52.5.213.57, ...\n",
            "Connecting to piazza.com (piazza.com)|54.205.50.50|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://d1b10bmlvqabco.cloudfront.net/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz [following]\n",
            "--2020-10-10 03:15:33--  https://d1b10bmlvqabco.cloudfront.net/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz\n",
            "Resolving d1b10bmlvqabco.cloudfront.net (d1b10bmlvqabco.cloudfront.net)... 99.86.33.8, 99.86.33.29, 99.86.33.155, ...\n",
            "Connecting to d1b10bmlvqabco.cloudfront.net (d1b10bmlvqabco.cloudfront.net)|99.86.33.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1533290 (1.5M) [application/x-gzip]\n",
            "Saving to: ‘./text_files.tar.gz’\n",
            "\n",
            "./text_files.tar.gz 100%[===================>]   1.46M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2020-10-10 03:15:33 (16.1 MB/s) - ‘./text_files.tar.gz’ saved [1533290/1533290]\n",
            "\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 5.1MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "file_len = 2579888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbcbgG7W0I04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9991143d-0e80-4374-d42c-0951dbe2f71c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh4RnbiSxmpm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "d7810a79-cfd6-4521-9f20-4af2560443ec"
      },
      "source": [
        "!pip install kaggle\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp '/content/drive/My Drive/Colab Notebooks/kaggle.json' ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!mkdir -p /content/data\n",
        "\n",
        "!kaggle datasets download -d ekrembayar/avatar-the-last-air-bender -p/content/data\n",
        "from zipfile import ZipFile\n",
        "with ZipFile(\"/content/data/avatar-the-last-air-bender.zip\", \"r\", ) as zip_ref:\n",
        "  zip_ref.extractall(\"/content/data\")\n",
        "\n",
        "import pandas as pd\n",
        "avatar_data = pd.read_csv(\"/content/data/avatar.csv\", encoding='windows-1252', usecols=[\"full_text\"])\n",
        "\n",
        "use_avatar = True\n",
        "\n",
        "print(avatar_data['full_text'][0][:200])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.8)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (0.0.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Downloading avatar-the-last-air-bender.zip to /content/data\n",
            "  0% 0.00/0.99M [00:00<?, ?B/s]\n",
            "100% 0.99M/0.99M [00:00<00:00, 69.6MB/s]\n",
            "Water. Earth. Fire. Air. My grandmother used to tell me stories about the old days: a time of peace when the Avatar kept balance between the Water Tribes, Earth Kingdom, Fire Nation and Air Nomads. Bu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FffY3veuCHoJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "71029254-a6b9-442b-9697-8d6bb4da2b0f"
      },
      "source": [
        "print(len(avatar_data['full_text']))\n",
        "print(sum([len(x) for x in avatar_data['full_text']]) / len(avatar_data['full_text']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13385\n",
            "134.47575644378034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxBeKeNjJ0NQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1e8f5cc1-a41d-48ad-d5c3-1c65a36ac883"
      },
      "source": [
        "chunk_len = 200\n",
        " \n",
        "def random_chunk():\n",
        "  if not use_avatar:\n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file[start_index:end_index]\n",
        "  else:\n",
        "    # index = random.randint(0, len(avatar_data['full_text']) - 1)\n",
        "    # final_string = avatar_data['full_text'][index][:chunk_len]\n",
        "    # while len(final_string) < chunk_len:\n",
        "    #   final_string += ' '\n",
        "    #   index = random.randint(0, len(avatar_data['full_text']) - 1)\n",
        "    #   final_string += avatar_data['full_text'][index][:chunk_len - len(final_string)]\n",
        "    # final_string = ''.join([a for a in final_string if a in all_characters])\n",
        "    num_chunks = 3\n",
        "    start_index = random.randint(0, len(avatar_data['full_text']) - (num_chunks + 1))\n",
        "    final_string = ''\n",
        "    for i in range(num_chunks):\n",
        "      final_string += avatar_data['full_text'][start_index + i] + ' '\n",
        "\n",
        "    final_string = ''.join([a for a in final_string if a in all_characters])\n",
        "    return final_string\n",
        "\n",
        "  \n",
        "print(random_chunk())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I'm saying, I love you! [He kisses her. After he pulls back, she embraces and kisses him back.] [After kissing for a while she pulls back, whispering slightly.] What are we doing? What our hearts have been telling us to do for a long, long time. Baby, [He moves Katara down to the side.] you're my forever girl. [Aang puckers up his lips for another kiss.] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On0_WitWJ99e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "31e77e5d-c54f-4488-e4cc-1cae4bedc979"
      },
      "source": [
        "import torch\n",
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "  tensor = torch.zeros(len(string)).long()\n",
        "  for c in range(len(string)):\n",
        "    try:\n",
        "      tensor[c] = all_characters.index(string[c])\n",
        "    except ValueError as e:\n",
        "      print(e, \"'\", string[c], \"'\")\n",
        "      raise e\n",
        "  return tensor.cuda()\n",
        "\n",
        "abcDEF_tensor = char_tensor('abcDEF')\n",
        "print(abcDEF_tensor)\n",
        "\n",
        "def tensor_char(tensor):\n",
        "  result_str = ''\n",
        "  for l in range(tensor.size()[0]):\n",
        "    result_str += all_characters[tensor[l]]\n",
        "  return result_str\n",
        "\n",
        "abcDEF_string = tensor_char(abcDEF_tensor)\n",
        "print(abcDEF_string)\n",
        "# twice_tensor = abcDEF_tensor.append(abcDEF_tensor)\n",
        "# print(tensor_char(twice_tensor))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10, 11, 12, 39, 40, 41], device='cuda:0')\n",
            "abcDEF\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYJPTLcaYmfI"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: Creating your own GRU cell \n",
        "\n",
        "**(Come back to this later - its defined here so that the GRU will be defined before it is used)**\n",
        "\n",
        "---\n",
        "\n",
        "The cell that you used in Part 1 was a pre-defined Pytorch layer. Now, write your own GRU class using the same parameters as the built-in Pytorch class does.\n",
        "\n",
        "Please try not to look at the GRU cell definition. The answer is right there in the code, and in theory, you could just cut-and-paste it. This bit is on your honor!\n",
        "\n",
        "**TODO:**\n",
        "* Create a custom GRU cell\n",
        "\n",
        "**DONE:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aavAv50ZKQ-F"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class GRU(nn.Module):\n",
        "  class GRU_UNIT(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "      super(GRU.GRU_UNIT, self).__init__()\n",
        "      self.input_size = input_size\n",
        "      self.hidden_size = hidden_size\n",
        "\n",
        "      self.W_xr = nn.Linear(input_size, hidden_size, False)\n",
        "      self.W_hr = nn.Linear(input_size, hidden_size, True)\n",
        "      \n",
        "      self.W_xz = nn.Linear(input_size, hidden_size, False)\n",
        "      self.W_hz = nn.Linear(input_size, hidden_size, True)\n",
        "\n",
        "      self.W_xh = nn.Linear(input_size, hidden_size, False)\n",
        "      self.W_hh = nn.Linear(input_size, hidden_size, True)\n",
        "\n",
        "    # def init_hidden(self):\n",
        "    #   return torch.zeros((1, self.hidden_size))\n",
        "      \n",
        "    \n",
        "    def forward(self, inputs, hidden):\n",
        "      r_t = torch.sigmoid(self.W_xr(inputs) + self.W_hr(hidden))\n",
        "      z_t = torch.sigmoid(self.W_xz(inputs) + self.W_hz(hidden))\n",
        "      print('w_xr', self.W_xr.weight.size(), 'input', inputs.size(), 'w_hr', self.W_hr.weight.size(), 'hidden', hidden.size())\n",
        "      print(\"r_t\", r_t.size(), \"z_t\", z_t.size())\n",
        "      h_prime = F.tanh(self.W_xh(inputs) + self.W_hh(torch.matmul(r_t, hidden)))\n",
        "      h_t = torch.matmul(z_t, hidden) + torch.matmul((1 - z_t), h_prime)\n",
        "      \n",
        "      return h_t, h_t\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, num_layers=1):\n",
        "    super(GRU, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # self.hiddens_h = []\n",
        "    self.blocks = nn.ModuleList()\n",
        "    for _i in range(self.num_layers):\n",
        "      self.blocks.append(self.GRU_UNIT(self.input_size, self.hidden_size))\n",
        "      # self.hiddens_h.append(self.blocks[-1].init_hidden())\n",
        "\n",
        "  # def init_hidden(self):\n",
        "  #   for i, block in enumerate(self.blocks):\n",
        "  #     self.hiddens_h[i] = block.init_hidden()\n",
        "  #   return self.hiddens_h[0]\n",
        "\n",
        "    \n",
        "  \n",
        "  def forward(self, inputs, hidden):\n",
        "    '''\n",
        "      # Each layer does the following:\n",
        "      # r_t = sigmoid(W_ir*x_t + b_ir + W_hr*h_(t-1) + b_hr)\n",
        "      # z_t = sigmoid(W_iz*x_t + b_iz + W_hz*h_(t-1) + b_hz)\n",
        "      # n_t = tanh(W_in*x_t + b_in + r_t**(W_hn*h_(t-1) + b_hn))\n",
        "      # h_(t) = (1 - z_t)**n_t + z_t**h_(t-1)\n",
        "      # Where ** is hadamard product (not matrix multiplication, but elementwise multiplication)\n",
        "    '''\n",
        "\n",
        "    # for i, block in enumerate(self.blocks):\n",
        "    #   inputs, self.hiddens_h[i] = block(inputs, self.hiddens_h[i] if i > 0 else hidden)\n",
        "\n",
        "    # return inputs, self.hiddens_h[-1]\n",
        "    for i in range(self.num_layers):\n",
        "      inputs, hidden[i] = self.blocks[i](inputs, hidden[i])\n",
        "    \n",
        "    return inputs, hidden\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtXdX-B_WiAY"
      },
      "source": [
        "---\n",
        "\n",
        "##  Part 1: Building a sequence to sequence model\n",
        "\n",
        "---\n",
        "\n",
        "Great! We have the data in a useable form. We can switch out which text file we are reading from, and trying to simulate.\n",
        "\n",
        "We now want to build out an RNN model, in this section, we will use all built in Pytorch pieces when building our RNN class.\n",
        "\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Create an RNN class that extends from nn.Module.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6tNdEnzWj5F"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, n_layers=1, soft_max=False):\n",
        "    super(RNN, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    \n",
        "    # more stuff here...\n",
        "    self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "    self.gru = nn.GRU(input_size=self.hidden_size, hidden_size=self.hidden_size, num_layers=self.n_layers)\n",
        "    self.linOut = nn.Linear(self.hidden_size, self.output_size)\n",
        "    self.softmax = nn.Softmax(dim=1) if soft_max is True else None\n",
        "\n",
        "  def forward(self, input_char, hidden):\n",
        "    # by reviewing the documentation, construct a forward function that properly uses the output\n",
        "    # of the GRU\n",
        "    # https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
        "\n",
        "    # stuff here\n",
        "    out_decoded = self.embedding(input_char).view(1, 1, -1)\n",
        "    out_decoded = F.relu(out_decoded)\n",
        "    out_decoded, hidden = self.gru(out_decoded, hidden)\n",
        "    out_decoded = self.linOut(out_decoded[0])\n",
        "    if self.softmax is not None:\n",
        "      out_decoded = self.softmax(out_decoded)\n",
        "    \n",
        "    return out_decoded, hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(self.n_layers, 1, self.hidden_size).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrhXghEPKD-5"
      },
      "source": [
        "def random_training_set():    \n",
        "  chunk = random_chunk()\n",
        "  inp = char_tensor(chunk[:-1])\n",
        "  target = char_tensor(chunk[1:])\n",
        "  return inp, target\n",
        "\n",
        "# print(random_training_set())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpiGObbBX0Mr"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 2: Sample text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "We now want to be able to train our network, and sample text after training.\n",
        "\n",
        "This function outlines how training a sequence style network goes. \n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Fill in the pieces.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ALC3Pf8Kbsi"
      },
      "source": [
        "# NOTE: decoder_optimizer, decoder, and criterion will be defined below as global variables\n",
        "def train(inp, target, per_char=True, teacher_forcing=True):\n",
        "  ## initialize hidden layers, set up gradient and loss \n",
        "    # your code here\n",
        "  ## /\n",
        "  inp_len = inp.size(0)\n",
        "  target_len = target.size(0)\n",
        "\n",
        "  decoder.train()\n",
        "  decoder_optimizer.zero_grad()\n",
        "  hidden = decoder.init_hidden()\n",
        "  # print(hidden.size())\n",
        "  # print(asgfae)\n",
        "  loss = 0\n",
        "  \n",
        "  # result = []\n",
        "  # more stuff here...\n",
        "  if per_char:\n",
        "    next_char = inp[0]\n",
        "    for index in range(inp_len):\n",
        "      output, hidden = decoder(next_char, hidden)\n",
        "      values, indicies = output.topk(1)\n",
        "      # print(values, indicies)\n",
        "      result_char = indicies.squeeze().detach()\n",
        "      # result.append(result_char)\n",
        "      if teacher_forcing:\n",
        "        next_char = target[index]\n",
        "      else:\n",
        "        next_char = result_char\n",
        "      # output.transpose_(1, 2)\n",
        "      # print(output.size(), output.squeeze().size(), target[index].view(-1).size())\n",
        "      loss += criterion(output, target[index].view(-1))\n",
        "\n",
        "  else:\n",
        "    result, hidden = decoder(inp, hidden)\n",
        "    loss += criterion(result, target)\n",
        "  \n",
        "  loss.backward()\n",
        "  decoder_optimizer.step()\n",
        "  \n",
        "  return loss.item() / target_len\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN06NUu3YRlz"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 3: Sample text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "You can at this time, if you choose, also write out your train loop boilerplate that samples random sequences and trains your RNN. This will be helpful to have working before writing your own GRU class.\n",
        "\n",
        "If you are finished training, or during training, and you want to sample from the network you may consider using the following function. If your RNN model is instantiated as `decoder`then this will probabilistically sample a sequence of length `predict_len`\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Fill out the evaluate function to generate text frome a primed string\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-bp-OZ1KjNh"
      },
      "source": [
        "def sample_outputs(output, temperature):\n",
        "    \"\"\"Takes in a vector of unnormalized probability weights and samples a character from the distribution\"\"\"\n",
        "    # print(output.size())\n",
        "    return torch.multinomial(torch.exp(output / temperature), 1)\n",
        "\n",
        "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
        "  ## initialize hidden state, initialize other useful variables\n",
        "    # your code here\n",
        "  ## /\n",
        "  torch.no_grad()\n",
        "  decoder.eval()\n",
        "  result_str = ''\n",
        "  tensor_str = char_tensor(prime_str)\n",
        "\n",
        "  hidden = decoder.init_hidden()\n",
        "\n",
        "  predicted = []\n",
        "\n",
        "  next_char = char_tensor(' ')\n",
        "  for i in range(predict_len):\n",
        "    next_char = tensor_str[i].unsqueeze(0).unsqueeze(0) if i < len(prime_str) else next_char\n",
        "    # print(next_char, next_char < len(all_characters), len(all_characters))\n",
        "    predicted.append(next_char)\n",
        "    output, hidden = decoder(next_char, hidden)\n",
        "    next_char = sample_outputs(output, temperature)\n",
        "    # predicted.append(next_char)\n",
        "\n",
        "  predicted.append(next_char)\n",
        "  # print(predicted)\n",
        "\n",
        "  predicted = torch.cat(predicted)\n",
        "  result_str = tensor_char(predicted)\n",
        "\n",
        "  return result_str\n",
        "\n",
        "\n",
        "# def scope(epoch):\n",
        "#   gc.collect()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du4AGA8PcFEW"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: (Create a GRU cell, requirements above)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFS2bpHSZEU6"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Part 5: Run it and generate some text!\n",
        "\n",
        "---\n",
        "\n",
        "Assuming everything has gone well, you should be able to run the main function in the scaffold code, using either your custom GRU cell or the built in layer, and see output something like this. I trained on the “lotr.txt” dataset, using chunk_length=200, hidden_size=100 for 2000 epochs gave.\n",
        "\n",
        "**TODO:** \n",
        "* Create some cool output\n",
        "\n",
        "**DONE:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nXFeCmdKodw"
      },
      "source": [
        "import time\n",
        "n_epochs = 7000\n",
        "print_every = 200\n",
        "plot_every = 10\n",
        "hidden_size = 200\n",
        "n_layers = 3\n",
        "lr = 0.001\n",
        " \n",
        "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "decoder = decoder.cuda()\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        " \n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKfozqw-6eqb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ce9a9de-70c2-4891-f3a9-1ef2364070be"
      },
      "source": [
        "\n",
        "# n_epochs = 2000 \n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  loss_ = train(*random_training_set())       \n",
        "  loss_avg += loss_\n",
        "\n",
        "  if epoch % print_every == 0:\n",
        "      print('[%s (%d %d%%) %.4f]' % (time.time() - start, epoch, epoch / n_epochs * 100, loss_))\n",
        "      print(evaluate('Wh', 100), '\\n')\n",
        "\n",
        "  if epoch % plot_every == 0:\n",
        "      all_losses.append(loss_avg / plot_every)\n",
        "      loss_avg = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[128.37408328056335 (200 2%) 2.6856]\n",
            "Whel tuat oolerhinrpirigea. rerson Tupan herovene lin. the thee oppetif. yhar'r. ifns hor it the Zy r \n",
            "\n",
            "[253.24490332603455 (400 5%) 2.2482]\n",
            "Whis inly and.] Whes it dall of fater of dong lisesed. [Aens. Souklusll hasto hice diellull add. Zuko \n",
            "\n",
            "[386.6027681827545 (600 8%) 1.6603]\n",
            "Why and danges hin fornt of the fiderly to kever stokey it of soth to at Sokka a watres but hears tim \n",
            "\n",
            "[493.6465849876404 (800 11%) 1.6084]\n",
            "Whot on down how heres. I'cross, and hond wern of led her aolled and smying! He bech mall intined, [P \n",
            "\n",
            "[626.6996891498566 (1000 14%) 1.2262]\n",
            "Whatwer, I'm father narly upward. We ba chall,. I trumbles for a gos and leaver tree stame. [Welling  \n",
            "\n",
            "[752.8695955276489 (1200 17%) 1.4795]\n",
            "What away. The can clive is expicl roff. Appa would show in the spearturing across and Sokka, and App \n",
            "\n",
            "[884.8338508605957 (1400 20%) 1.3625]\n",
            "What? [Aver his hand.] I'm before the side-view of her. [To poisletion.] you holding the Beet his see \n",
            "\n",
            "[1025.7898638248444 (1600 22%) 1.6780]\n",
            "Whip's anyther and the will tried from the ground. But who ling I destreet of almore a fadered. It do \n",
            "\n",
            "[1146.0771579742432 (1800 25%) 1.3253]\n",
            "What to guards I wide son you ane more, the lad. Fo you leaving to get to star. Katara. You'll the yu \n",
            "\n",
            "[1276.2101573944092 (2000 28%) 1.3010]\n",
            "What? [Cut to the engion.] I canctuve your tell, and a geers on the sound they desce beto his stare b \n",
            "\n",
            "[1403.6184623241425 (2200 31%) 1.4683]\n",
            "What? Sokka raises the temple. She siles Cut to two catches the bangdom of the balce.\n",
            "The bogents to \n",
            "\n",
            "[1538.4754524230957 (2400 34%) 1.3723]\n",
            "Who dogng slowly, Yue stands edge pair. He lifts from the wolder. That you if you know! I'm tranny on \n",
            "\n",
            "[1667.729970216751 (2600 37%) 1.3595]\n",
            "What she around there? That me. Pather? [Angrily.] Here, how the man is sender you for water I charge \n",
            "\n",
            "[1796.5539627075195 (2800 40%) 1.1992]\n",
            "What is the mare! [His turns to get on Zuko.] And you guess ever to free the tea, I want to the order \n",
            "\n",
            "[1919.6501636505127 (3000 42%) 1.2855]\n",
            "Whresh I don't ready for at earthbending. It's see you got! [Close-up of Each Sokka, who stands to To \n",
            "\n",
            "[2051.4497323036194 (3200 45%) 1.1872]\n",
            "Why don't really we got my low a tribe, not feels a big again. They are changes in front of the scene \n",
            "\n",
            "[2206.9525558948517 (3400 48%) 1.2813]\n",
            "What are not bender of mech. What are you're too. [Standing manage.] I think Katara flame. Cut to a c \n",
            "\n",
            "[2332.539281606674 (3600 51%) 1.4455]\n",
            "Why we plact to message out the street. [Pests the carten catches the camera.] Like the first you hav \n",
            "\n",
            "[2457.890967607498 (3800 54%) 1.2941]\n",
            "What's who create, [Looking on I can cheek.] All wait, [Grabs his own is being.] Let that is on there \n",
            "\n",
            "[2594.4618723392487 (4000 57%) 1.2145]\n",
            "What he little proby my proucty is little pering profe the world. The encasis caused before crowdy Ka \n",
            "\n",
            "[2714.5507996082306 (4200 60%) 1.3869]\n",
            "What we're when It like it will the Bactother? [Laughs ... Zuko is prince a shaud. Scene cut to a Cro \n",
            "\n",
            "[2841.7748324871063 (4400 62%) 1.2332]\n",
            "What that has this the seen for the same it approach Toph as he breath! A use and Katara and Aang com \n",
            "\n",
            "[2964.4639344215393 (4600 65%) 0.9971]\n",
            "What do for the stured when he saying the staff curle. The camera zooms it to a show of the leaver of \n",
            "\n",
            "[3100.2394626140594 (4800 68%) 1.1717]\n",
            "When the two are catches off. Pads of the colone. [Appa off the sword comes as he tugs to come of try \n",
            "\n",
            "[3217.567898273468 (5000 71%) 1.0585]\n",
            "What was hours ... I'm not meet so earthbending. [He makes Aang and Sokka is propeling away.] Someone \n",
            "\n",
            "[3340.666910648346 (5200 74%) 1.0962]\n",
            "What didn't know we can a little seen from the mountain. Sokka step out of him with Aang's snow. The  \n",
            "\n",
            "[3462.4263615608215 (5400 77%) 1.1664]\n",
            "What about head? He'll emerge? [Katara gottless goes in his eyes.] It looks good, it turning these de \n",
            "\n",
            "[3590.8896205425262 (5600 80%) 1.3443]\n",
            "What imposted. [Side-view of Appa's hands in front.] I'm sorry to need you here all me to be the will \n",
            "\n",
            "[3726.7331500053406 (5800 82%) 1.2962]\n",
            "What didn't keep about an enough of you forgive his back. [Points airbending.] Other tried eye, Zuko, \n",
            "\n",
            "[3864.2723746299744 (6000 85%) 1.1892]\n",
            "What do you mean to my need to see you. Toph beginns to make him in performs. Cut to Zuko's staff. Fa \n",
            "\n",
            "[4000.386323451996 (6200 88%) 1.3900]\n",
            "What did the Fire Nation arouno sealing that seccept does! He's talk again that I do it. [Frontal sho \n",
            "\n",
            "[4129.927583217621 (6400 91%) 1.2061]\n",
            "What do? [Tone scarded.] All the girls find your plan? [Caserally as Toph and Sokka laugh and swings  \n",
            "\n",
            "[4249.245774507523 (6600 94%) 1.1432]\n",
            "What's me. I might are now. The thought that I get there, but I'm greet the while wests the camera mo \n",
            "\n",
            "[4376.143546581268 (6800 97%) 1.2496]\n",
            "What is here? [Siting on his cheers.] \"mmm. [Leavers are painting towering again.] And you're guys. B \n",
            "\n",
            "[4506.374228239059 (7000 100%) 0.9898]\n",
            "Why do you had their having not hear that way. It polet near ... [Completely.] They're want to do som \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee0so6aKJ5L8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "f0a806a4-6f4d-4298-e775-119fad716cdd"
      },
      "source": [
        "for i in range(10):\n",
        "  start_strings = [\" Th\", \" wh\", \" he\", \" I \", \" ca\", \" G\", \" lo\", \" ra\"]\n",
        "  start = random.randint(0,len(start_strings)-1)\n",
        "  print(start_strings[start])\n",
        "#   all_characters.index(string[c])\n",
        "  print(evaluate(start_strings[start], 200), '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " wh\n",
            " who the camera puried sliding pointing down to Azula. He looks at the two clouds as the the screen picks her left that the positure ensose in the side. [Shoutside the point of side of the chitters and \n",
            "\n",
            " ca\n",
            " cample thanks at his painted for a point to compley at the news. Good inside the darkens under the mountainated in the corning here. She looks at Ty Lee as they look around to control a blast at Azula \n",
            "\n",
            " ca\n",
            " can time to landed to this arrow. Cuts to Aang, who had a plamated reaching the doorway rises. Standing up the edgatures around the cliff considered. Cuts to Azula, who long with forth and looks to pr \n",
            "\n",
            " lo\n",
            " looks at her.] This first is in the temple. Katara did an energy leaps impacts the wall, who die approaching the sourcated in the count friend. It's because this. It can find someone is trying to comm \n",
            "\n",
            " G\n",
            " Grai.] If you feel this time humble going the ends up I'm indowing here. Concentrations one lost what? You ... I think I think perspective oh nothing. Zuko! [They huddle and kneels the campsible.] Sor \n",
            "\n",
            " he\n",
            " hear the first have to be supple heady. It's too, holding him. I'm the beach of their attempt to do. [The camera pans to show the simbles face in a ponch.] Chank of the two possion earthbenders wear a \n",
            "\n",
            " ca\n",
            " catches the three air arm around the three, raised glider their shoulder. The first looks at the sandfortable thanks onto the tunnel of the dirt. Aang off the real Team Avatar is still be sourt her as \n",
            "\n",
            " Th\n",
            " The Sokka approaching as the camera panning arrow for the half.] Us it's that just the down in the spirit. [Carched.] You should think we got around here out it cloud. [Aang lands on the mount arrow h \n",
            "\n",
            " I \n",
            " I can't catch them over here me. She had sent the way onto the Fire Lord body building that defered. Aang reaches the side of the corner and survified chase. Hey, they're this idea the corridiant seve \n",
            "\n",
            " wh\n",
            " whip to the camera. She's body to the iceberg. You little like helpyed, Zhao, let's going to watch a chicken first have fired and leaps in front of her disappear. [Close-up of the now of the water att \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM168PBF39-q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "1744e85b-76b2-4c91-b3fe-d7bd3e8120d4"
      },
      "source": [
        "def evaluate_sentences(prime_str='A', sentences=5, temperature=0.8):\n",
        "  ## initialize hidden state, initialize other useful variables\n",
        "    # your code here\n",
        "  ## /\n",
        "  torch.no_grad()\n",
        "  decoder.eval()\n",
        "  result_str = ''\n",
        "  tensor_str = char_tensor(prime_str)\n",
        "\n",
        "  hidden = decoder.init_hidden()\n",
        "\n",
        "  predicted = []\n",
        "\n",
        "  next_char = char_tensor(' ')\n",
        "  for _i in range(sentences):\n",
        "    while len(result_str) == 0 or result_str[-1] != '.':\n",
        "      next_char = tensor_str[i].unsqueeze(0).unsqueeze(0) if i < len(prime_str) else next_char\n",
        "      result_str += tensor_char(next_char)\n",
        "      output, hidden = decoder(next_char, hidden)\n",
        "      next_char = sample_outputs(output, temperature)\n",
        "    result_str += ' '\n",
        "  result_str += tensor_char(next_char)\n",
        "\n",
        "\n",
        "  return result_str\n",
        "\n",
        "print(evaluate_sentences(\"H\"), '\\n')\n",
        "print(evaluate(\"Zuko and Aang \", 300), '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Sokka up the was boudly.  Azula lifts the first pulls up a rock toward the last walks onto the room.  He luts and looks at a mower who is amproaching the city.  Aang proceeds and narrows and arm continues to the blast of his return passed again.  Cuts to shot of the two ship turns out of the sandbence.   \n",
            "\n",
            "Zuko and Aang as the camera shows her latter before the four machine and stop well in the armor. Cuts to shot of Azula. Because the camera zooms to the circle as Painted Lady animal through this time. [Annoyance the think coans.] I that didn't master this ice on here, but you're talking before. I let \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJhgDc2IauPE"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 6: Generate output on a different dataset\n",
        "\n",
        "---\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "\n",
        "\n",
        "**DONE:**\n",
        "* Choose a textual dataset. Here are some [text datasets](https://www.kaggle.com/datasets?tags=14104-text+data%2C13205-text+mining) from Kaggle \n",
        "\n",
        "* Generate some decent looking results and evaluate your model's performance (say what it did well / not so well)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNjqB-6R7jqm"
      },
      "source": [
        "## What it did well:\n",
        "* Opening and closing brackets\n",
        "* Capitalizing proper names\n",
        "* Narration notes in brackets, dialogue outside\n",
        "* Beginning of sentence capitalizaiton\n",
        "\n",
        "## What it did poorly:\n",
        "* Loats of speelling mistkes (I did that on purpose)\n",
        "* Perhaps this comes becuase of how `evaluate` works, but not always ending sentences with punctuation? (Could be different based on how I use my dataset)\n",
        "* Gender consistency\n",
        "* Scene consistency (needs to remember more, perhaps over a scene)"
      ]
    }
  ]
}