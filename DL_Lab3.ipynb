{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DL_Lab3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpkT2EpSqL6i",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wingated/cs474_labs_f2019/blob/master/DL_Lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "# Lab 3: Intro to CNNs and DNNs\n",
        "\n",
        "## Objectives\n",
        "\n",
        "* Build and train a deep conv net\n",
        "* Explore and implement various initialization techniques\n",
        "* Implement a parameterized module in Pytorch\n",
        "* Use a principled loss function\n",
        "\n",
        "## Video Tutorial\n",
        "[https://youtu.be/3TAuTcx-VCc](https://youtu.be/3TAuTcx-VCc)\n",
        "\n",
        "## Deliverable\n",
        "For this lab, you will submit an ipython notebook via learningsuite.\n",
        "This is where you build your first deep neural network!\n",
        "\n",
        "For this lab, we'll be combining several different concepts that we've covered during class,\n",
        "including new layer types, initialization strategies, and an understanding of convolutions.\n",
        "\n",
        "## Grading Standards:\n",
        "* 30% Part 0: Successfully followed lab video and typed in code\n",
        "* 20% Part 1: Re-implement Conv2D and CrossEntropy loss function\n",
        "* 20% Part 2: Implement different initialization strategies\n",
        "* 10% Part 3: Print parameters, plot train/test accuracy\n",
        "* 10% Part 4: Convolution parameters quiz\n",
        "* 10% Tidy and legible figures, including labeled axes where appropriate\n",
        "___\n",
        "\n",
        "### Part 0\n",
        "Watch and follow video tutorial:\n",
        "\n",
        "[https://youtu.be/3TAuTcx-VCc](https://youtu.be/3TAuTcx-VCc)\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "* Watch tutorial\n",
        "\n",
        "**DONE:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-r3t4nnPqL6t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "e914fbf5-5539-4c58-f382-2d3b11b1ae55"
      },
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.7.0+cu101)\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->torchvision) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKLoJGI2qL7D",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wQOefmcZVgTl",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "\n",
        "assert torch.cuda.is_available(), \"You need to request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Il_53HLSWPTY",
        "colab": {}
      },
      "source": [
        "from torch.nn.parameter import Parameter\n",
        "import pdb"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RkieTbwlYWPS",
        "colab": {}
      },
      "source": [
        "class CrossEntropyLoss(nn.Module):\n",
        "  pass\n",
        "\n",
        "class Conv2d(nn.Module):\n",
        "  def __init__(self, n_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
        "    self.__dict__.update(locals()) # debatable\n",
        "    super(Conv2d, self).__init__()\n",
        "\n",
        "    # (out, in, k, k)\n",
        "    self.weight = Parameter(torch.Tensor(self.out_channels,\n",
        "                               self.n_channels,\n",
        "                               kernel_size[0],\n",
        "                               kernel_size[1]))\n",
        "    self.bias = Parameter(torch.Tensor(self.out_channels))\n",
        "\n",
        "    # initialize weights and bias\n",
        "\n",
        "  def forward(self, x):\n",
        "    return F.conv2d(x, self.weight, self.bias, self.stride, self.padding,\n",
        "                    self.dilation, self.groups)\n",
        "  \n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d4C-_v9Hm7YE",
        "colab": {}
      },
      "source": [
        "class ConvNetwork(nn.Module):\n",
        "  def __init__(self, dataset):\n",
        "    super(ConvNetwork, self).__init__()\n",
        "    x, y = dataset[0]\n",
        "    c, h, w = x.size()\n",
        "    output = 10\n",
        "\n",
        "    self.net = nn.Sequential(Conv2d(c, 10, (3, 3), padding=(1,1)), \n",
        "                             Conv2d(10, output, (28, 28), padding=(0,0)),\n",
        "                             )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    #n, c, h, w = x.size()\n",
        "    return self.net(x).squeeze(2).squeeze(2)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt9jbJZx7ayz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the dataset class you created in lab2\n",
        "class LinearNetwork(nn.Module):\n",
        "  def __init__(self, dataset):\n",
        "    super(LinearNetwork, self).__init__()\n",
        "    x, y = dataset[0]\n",
        "    c, h, w = x.size()\n",
        "    out_dim = 10 # hardcoded\n",
        "\n",
        "    self.net = nn.Sequential(nn.Linear(c * h * w, 1000),\n",
        "                             nn.ReLU(),\n",
        "                             nn.Linear(1000, out_dim))\n",
        "    \n",
        "  def forward(self, x):\n",
        "    n, c, h, w = x.size()\n",
        "    flattened = x.view(n, c * h * w)\n",
        "    return self.net(flattened)\n",
        "\n",
        "\n",
        "class FashionMNISTProcessedDataset(Dataset):\n",
        "  def __init__(self, root, train=True):\n",
        "    self.data = datasets.FashionMNIST(root, train=train, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    x, y = self.data[i]\n",
        "    return x, y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "867FL98k8Nkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = FashionMNISTProcessedDataset('/tmp/fashionmnist', train=True)\n",
        "val_dataset = FashionMNISTProcessedDataset('/tmp/fashionmnist', train=False)\n",
        "model = LinearNetwork(train_dataset)\n",
        "model = model.cuda()\n",
        "train_loader = DataLoader(train_dataset, batch_size=42, pin_memory=True)\n",
        "validation_loader = DataLoader(val_dataset, batch_size=42, pin_memory=True)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "objective = nn.CrossEntropyLoss()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOipT1A3dqyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validations = []\n",
        "losses = []"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMnlf_UGdzMF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6615c0d7-4856-4274-8df3-1e7942141687"
      },
      "source": [
        "num_epochs = 1\n",
        "update_epoch = 100\n",
        "for epoch in range(num_epochs):\n",
        "  loop = tqdm(total=len(train_loader) * num_epochs, position=0)\n",
        "\n",
        "  for batch, (x, y_truth) in enumerate(train_loader):\n",
        "    # learn\n",
        "    x, y_truth = x.cuda(non_blocking=True), y_truth.cuda(non_blocking=True)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    y_hat = model(x)\n",
        "    loss = objective(y_hat, y_truth)\n",
        "\n",
        "    loss.backward()\n",
        "    accuracy = 0 # TODO: we do ourself\n",
        "    loop.set_description('epoch:{} loss:{:.4f} accuracy:{:.3f}'.format(epoch, loss.item(), accuracy))\n",
        "    loop.update(1)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % update_epoch == 0:\n",
        "      val = np.mean([objective(model(x.cuda()), y.cuda()).item() for x, y in validation_loader])\n",
        "      validations.append((len(losses), val))\n",
        "\n",
        "  loop.close()\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0 loss:0.4651 accuracy:0.000: 100%|██████████| 1429/1429 [00:19<00:00, 71.70it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i91yfU01gi4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8239e8e3-6766-4232-d1e5-4b4e93c84157"
      },
      "source": [
        "## plot\n",
        "\n",
        "a, b = zip(*validations)\n",
        "plt.plot(losses, label='train')\n",
        "plt.plot(a, b, label='val')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVMklEQVR4nO3df5BX9X3v8edb2IAoqQusYgED6TiJvwI2G6Sjc4O3NwRMFW9tgl6TmLSGmXvNTfTWO5c2nWjVP2w6tz+8ieWSlDGZUYzVeKVTjMFWQnPV1MVLIyoKog6LGhZQA400kr7vH9+Dfl33x3d3v/uDD8/HzJk95/P5nLPvDzvz2sM557snMhNJUrmOGe0CJEnDy6CXpMIZ9JJUOINekgpn0EtS4caPdgE9mTZtWs6ePXu0y5CkI8amTZv2ZGZbT31jMuhnz55NR0fHaJchSUeMiHixtz4v3UhS4Qx6SSqcQS9JhRuT1+glaaDefPNNOjs7OXjw4GiXMqwmTpzIzJkzaWlpaXgfg15SETo7O5k8eTKzZ88mIka7nGGRmezdu5fOzk7mzJnT8H5eupFUhIMHDzJ16tRiQx4gIpg6deqA/9di0EsqRskhf9hg5mjQS426f0VtkY4wBr3UqFeeqC1SD1577TVuvfXWAe93wQUX8Nprrw1DRW/rN+gjYlZEPBQRT0XEkxHx5R7GXB4RP4mIJyLi4YiYW9f3QtW+OSL8uKukIvUW9IcOHepzv3Xr1nHCCScMV1lAY0/dHAJ+PzMfj4jJwKaIWJ+ZT9WNeR74aGa+GhFLgFXAOXX952fmnuaVLUljy4oVK3juueeYN28eLS0tTJw4kdbWVrZu3cqzzz7LxRdfzM6dOzl48CBf/vKXWb58OfD2n3w5cOAAS5Ys4bzzzuPhhx9mxowZ3HfffRx77LFDrq3foM/Ml4GXq/X9EfE0MAN4qm7Mw3W7PArMHHJlkjRIf/y3T/LUSz9r6jFP/9X3ct2FZ/Taf/PNN7NlyxY2b97Mhg0b+MQnPsGWLVveegxy9erVTJkyhTfeeIOPfOQjXHLJJUydOvUdx9i2bRtr1qzhm9/8Jp/61Ke45557+PSnPz3k2gd0jT4iZgNnAz/uY9jvAffXbSfwg4jYFBHL+zj28ojoiIiOrq6ugZQlSWPO/Pnz3/Gs+y233MLcuXNZsGABO3fuZNu2be/aZ86cOcybNw+AD3/4w7zwwgtNqaXhD0xFxPHAPcDVmdnjr8qIOJ9a0J9X13xeZu6KiBOB9RGxNTM3dt83M1dRu+RDe3u7byyXNGh9nXmPlOOOO+6t9Q0bNvDggw/yyCOPMGnSJBYuXNjjs/ATJkx4a33cuHG88cYbTamloTP6iGihFvK3Z+b3ehnzIeBbwNLM3Hu4PTN3VV93A/cC84datCSNNZMnT2b//v099r3++uu0trYyadIktm7dyqOPPjqitfV7Rh+1p/P/Gng6M/+slzGnAN8DPpOZz9a1HwccU13bPw5YBNzQlMolaQyZOnUq5557LmeeeSbHHnssJ5100lt9ixcvZuXKlZx22ml84AMfYMGCBSNaWyOXbs4FPgM8ERGbq7Y/BE4ByMyVwFeBqcCt1ae2DmVmO3AScG/VNh64IzO/39QZSNIYcccdd/TYPmHCBO6///4e+w5fh582bRpbtmx5q/3aa69tWl2NPHXzI6DPz9xm5pXAlT207wDmvnsPSdJI8ZOxklQ4g16SCmfQS1LhDHpJKpxBL0mFM+glaRQcf/zxI/a9DHpJKpwvB5ekJlixYgWzZs3iqquuAuD6669n/PjxPPTQQ7z66qu8+eab3HTTTSxdunTEazPoJZXn/hXNfxvY9LNgyc29di9btoyrr776raC/6667eOCBB/jSl77Ee9/7Xvbs2cOCBQu46KKLRvzdtga9JDXB2Wefze7du3nppZfo6uqitbWV6dOnc80117Bx40aOOeYYdu3axU9/+lOmT58+orUZ9JLK08eZ93D65Cc/yd13380rr7zCsmXLuP322+nq6mLTpk20tLQwe/bsHv888XAz6CWpSZYtW8YXvvAF9uzZww9/+EPuuusuTjzxRFpaWnjooYd48cUXR6Uug16SmuSMM85g//79zJgxg5NPPpnLL7+cCy+8kLPOOov29nY++MEPjkpdBr0kNdETT7x9E3jatGk88sgjPY47cODASJXkc/SSVDqDXpIKZ9BLKkZmjnYJw24wczToJRVh4sSJ7N27t+iwz0z27t3LxIkTB7SfN2MlFWHmzJl0dnbS1dU12qUMq4kTJzJz5swB7dNv0EfELOA71F70ncCqzPzLbmMC+EvgAuDnwOcy8/Gq7wrgj6qhN2XmtwdUoSQ1oKWlhTlz5ox2GWNSI2f0h4Dfz8zHI2IysCki1mfmU3VjlgCnVss5wF8B50TEFOA6oJ3aL4lNEbE2M19t6iwkSb3q9xp9Zr58+Ow8M/cDTwMzug1bCnwnax4FToiIk4GPA+szc18V7uuBxU2dgSSpTwO6GRsRs4GzgR9365oB7Kzb7qzaemvv6djLI6IjIjpKv8YmSSOp4aCPiOOBe4CrM/NnzS4kM1dlZntmtre1tTX78JJ01Goo6COihVrI356Z3+thyC5gVt32zKqtt3ZJ0gjpN+irJ2r+Gng6M/+sl2Frgc9GzQLg9cx8GXgAWBQRrRHRCiyq2iRJI6SRp27OBT4DPBERm6u2PwROAcjMlcA6ao9Wbqf2eOXnq759EXEj8Fi13w2Zua955UuS+tNv0Gfmj4A+33uVtY+iXdVL32pg9aCqkyQNmX8CQZIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4fp9lWBErAZ+C9idmWf20P/fgcvrjnca0Fa9L/YFYD/wS+BQZrY3q3BJUmMaOaO/DVjcW2dm/mlmzsvMecAfAD/s9gLw86t+Q16SRkG/QZ+ZG4F9/Y2rXAasGVJFkqSmato1+oiYRO3M/5665gR+EBGbImJ5P/svj4iOiOjo6upqVlmSdNRr5s3YC4H/2+2yzXmZ+evAEuCqiPh3ve2cmasysz0z29va2ppYliQd3ZoZ9JfS7bJNZu6qvu4G7gXmN/H7SZIa0JSgj4hfAT4K3FfXdlxETD68DiwCtjTj+0mSGtfI45VrgIXAtIjoBK4DWgAyc2U17D8CP8jMf6nb9STg3og4/H3uyMzvN690SVIj+g36zLysgTG3UXsMs75tBzB3sIVJkprDT8ZKUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9Jhes36CNidUTsjogtvfQvjIjXI2JztXy1rm9xRDwTEdsjYkUzC5ckNaaRM/rbgMX9jPnHzJxXLTcARMQ44BvAEuB04LKIOH0oxUqSBq7foM/MjcC+QRx7PrA9M3dk5i+AO4GlgziOJGkImnWN/jci4p8j4v6IOKNqmwHsrBvTWbX1KCKWR0RHRHR0dXU1qSxJUjOC/nHgfZk5F/hfwP8ZzEEyc1Vmtmdme1tbWxPKkiRBE4I+M3+WmQeq9XVAS0RMA3YBs+qGzqzaJEkjaMhBHxHTIyKq9fnVMfcCjwGnRsSciHgPcCmwdqjfT5I0MOP7GxARa4CFwLSI6ASuA1oAMnMl8DvAf46IQ8AbwKWZmcChiPgi8AAwDlidmU8OyywkSb3qN+gz87J++r8OfL2XvnXAusGVJklqBj8ZK0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9JhTPoJalwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBWu36CPiNURsTsitvTSf3lE/CQinoiIhyNibl3fC1X75ojoaGbhkqTGNHJGfxuwuI/+54GPZuZZwI3Aqm7952fmvMxsH1yJkqShGN/fgMzcGBGz++h/uG7zUWDm0MuSJDVLs6/R/x5wf912Aj+IiE0RsbyvHSNieUR0RERHV1dXk8uSpKNXv2f0jYqI86kF/Xl1zedl5q6IOBFYHxFbM3NjT/tn5iqqyz7t7e3ZrLok6WjXlDP6iPgQ8C1gaWbuPdyembuqr7uBe4H5zfh+kqTGDTnoI+IU4HvAZzLz2br24yJi8uF1YBHQ45M7kqTh0++lm4hYAywEpkVEJ3Ad0AKQmSuBrwJTgVsjAuBQ9YTNScC9Vdt44I7M/P4wzEGS1IdGnrq5rJ/+K4Ere2jfAcx99x6SpJHkJ2MlqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9JhTPoJalwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBWuoaCPiNURsTsieny5d9TcEhHbI+InEfHrdX1XRMS2armiWYVLkhrT6Bn9bcDiPvqXAKdWy3LgrwAiYgq1l4mfA8wHrouI1sEWK0kauIaCPjM3Avv6GLIU+E7WPAqcEBEnAx8H1mfmvsx8FVhP378wJElN1qxr9DOAnXXbnVVbb+3vEhHLI6IjIjq6urqaVJYkaczcjM3MVZnZnpntbW1to12OJBWjWUG/C5hVtz2zauutXZI0QpoV9GuBz1ZP3ywAXs/Ml4EHgEUR0VrdhF1UtUmSRsj4RgZFxBpgITAtIjqpPUnTApCZK4F1wAXAduDnwOervn0RcSPwWHWoGzKzr5u6kqQmayjoM/OyfvoTuKqXvtXA6oGXJklqhjFzM1aSNDwMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9JhWso6CNicUQ8ExHbI2JFD/1/HhGbq+XZiHitru+XdX1rm1m8JKl//b4cPCLGAd8APgZ0Ao9FxNrMfOrwmMy8pm78fwXOrjvEG5k5r3klS5IGopEz+vnA9szckZm/AO4ElvYx/jJgTTOKkyQNXSNBPwPYWbfdWbW9S0S8D5gD/ENd88SI6IiIRyPi4t6+SUQsr8Z1dHV1NVCWJKkRzb4Zeylwd2b+sq7tfZnZDvwn4C8i4td62jEzV2Vme2a2t7W1NbksSTp6NRL0u4BZddszq7aeXEq3yzaZuav6ugPYwDuv30uShlkjQf8YcGpEzImI91AL83c9PRMRHwRagUfq2lojYkK1Pg04F3iq+76SpOHT71M3mXkoIr4IPACMA1Zn5pMRcQPQkZmHQ/9S4M7MzLrdTwP+d0T8G7VfKjfXP60jSRp+/QY9QGauA9Z1a/tqt+3re9jvYeCsIdQnSRoiPxkrSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9JhWvoDVOSgBd/NNoVSIPiGb0kFa6hoI+IxRHxTERsj4gVPfR/LiK6ImJztVxZ13dFRGyrliuaWbwkqX/9XrqJiHHAN4CPAZ3AYxGxNjOf6jb0u5n5xW77TgGuA9qBBDZV+77alOolSf1q5Ix+PrA9M3dk5i+AO4GlDR7/48D6zNxXhft6YPHgSpUkDUYjQT8D2Fm33Vm1dXdJRPwkIu6OiFkD3JeIWB4RHRHR0dXV1UBZ0gh7/8LaIh1hmnUz9m+B2Zn5IWpn7d8e6AEyc1Vmtmdme1tbW5PKkpros/fVFukI00jQ7wJm1W3PrNrekpl7M/Nfq81vAR9udF9J0vBqJOgfA06NiDkR8R7gUmBt/YCIOLlu8yLg6Wr9AWBRRLRGRCuwqGqTJI2Qfp+6ycxDEfFFagE9DlidmU9GxA1AR2auBb4UERcBh4B9wOeqffdFxI3UflkA3JCZ+4ZhHpKkXkRmjnYN79Le3p4dHR2jXYYkHTEiYlNmtvfU5ydjJalwBr0kFc6gl6TCGfSSVLgxeTM2IrqAF0e7jgGaBuwZ7SJGmHM+OjjnI8P7MrPHT5uOyaA/EkVER293vEvlnI8OzvnI56UbSSqcQS9JhTPom2fVaBcwCpzz0cE5H+G8Ri9JhfOMXpIKZ9BLUuEM+gGIiCkRsb560fn66k8v9zSuzxeiR8TaiNgy/BUP3VDmHBGTIuLvImJrRDwZETePbPUDExGLI+KZiNgeESt66J8QEd+t+n8cEbPr+v6gan8mIj4+knUP1mDnGxEfi4hNEfFE9fXfj3TtgzWUn3HVf0pEHIiIa0eq5qbITJcGF+BrwIpqfQXwJz2MmQLsqL62Vuutdf2/DdwBbBnt+Qz3nIFJwPnVmPcA/wgsGe059TLPccBzwPurWv8ZOL3bmP8CrKzWLwW+W62fXo2fAMypjjNutOc0jPM9G/jVav1MYNdoz2e451zXfzfwN8C1oz2fgSye0Q/MUt5+TeK3gYt7GNPrC9Ej4njgvwE3jUCtzTLoOWfmzzPzIYCsvVj+cWpvGRuL5gPbM3NHVeud1OZer/7f4m7gNyMiqvY7M/NfM/N5YHt1vLFs0PPNzP+XmS9V7U8Cx0bEhBGpemiG8jMmIi4Gnqc25yOKQT8wJ2Xmy9X6K8BJPYzp64XoNwL/E/j5sFXYfEOdMwARcQJwIfD3w1FkEzTyIvu3xmTmIeB1YGqD+441Q5lvvUuAx/PtV4mOZYOec3WS9j+APx6BOpuu3zdMHW0i4kFgeg9dX6nfyMyMiIafTY2IecCvZeY13a/7jbbhmnPd8ccDa4BbMnPH4KrUWBMRZwB/Qu0VoaW7HvjzzDxQneAfUQz6bjLzP/TWFxE/jYiTM/Pl6j25u3sYtgtYWLc9E9gA/AbQHhEvUPt3PzEiNmTmQkbZMM75sFXAtsz8iyaUO1waeZH94TGd1S+vXwH2NrjvWDOU+RIRM4F7gc9m5nPDX25TDGXO5wC/ExFfA04A/i0iDmbm14e/7CYY7ZsER9IC/CnvvDH5tR7GTKF2Ha+1Wp4HpnQbM5sj52bskOZM7X7EPcAxoz2XfuY5ntpN5Dm8faPujG5jruKdN+ruqtbP4J03Y3cw9m/GDmW+J1Tjf3u05zFSc+425nqOsJuxo17AkbRQuz7598A24MG6MGsHvlU37nep3ZDbDny+h+McSUE/6DlTO2NK4Glgc7VcOdpz6mOuFwDPUnsy4ytV2w3ARdX6RGpPXGwH/gl4f92+X6n2e4Yx+mRRs+YL/BHwL3U/083AiaM9n+H+Gdcd44gLev8EgiQVzqduJKlwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuEMekkq3P8HX49a/60ZPy4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QY4owfQwm-Ni"
      },
      "source": [
        "___\n",
        "\n",
        "### Part 1\n",
        "Re-implement a Conv2D module with parameters and a CrossEntropy loss function.\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "* CrossEntropyLoss \n",
        "* Conv2D\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "___\n",
        "\n",
        "### Part 2\n",
        "Implement a few initialization strategies which can include Xe initialization\n",
        "(sometimes called Xavier), Orthogonal initialization, and uniform random.\n",
        "You can specify which strategy you want to use with a parameter. \n",
        "\n",
        "\n",
        "\n",
        "Helpful links include:\n",
        "*  [Orthogonal Initialization](https://hjweide.github.io/orthogonal-initialization-in-convolutional-layers) (or the original paper: http://arxiv.org/abs/1312.6120)\n",
        "*  http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization\n",
        "\n",
        "**TODO:**\n",
        "* Parameterize custom Conv2D for different initilization strategies\n",
        "* Xe\n",
        "* Orthogonal\n",
        "* Uniform\n",
        "\n",
        "**DONE:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ronkEckHiDaU"
      },
      "source": [
        "\n",
        "___\n",
        "\n",
        "### Part 3\n",
        "Print the number of parameters in your network and plot accuracy of your training and validation \n",
        "set over time. You should experiment with some deep networks and see if you can get a network \n",
        "with close to 1,000,000 parameters.\n",
        "\n",
        "**TODO:**\n",
        "* Experiment with Deep Networks\n",
        "* Plot accuracy of training and validation set over time\n",
        "* Print out number of parameters in the model \n",
        "\n",
        "**DONE:**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PaWCKjxvyRSf",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "\n",
        "# Go back up and try a few different networks and initialization strategies\n",
        "# Plot loss if you want\n",
        "# Plot accuracy\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oijCR-JnyS6V",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "# Compute and print the number of parameters in the model\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7hXGRxUQh9gX"
      },
      "source": [
        "___\n",
        "\n",
        "### Part 4\n",
        "Learn about how convolution layers affect the shape of outputs, and answer the following quiz questions. Include these in a new markdown cell in your jupyter notebook.\n",
        "\n",
        "\n",
        "*Using a Kernel size of 3×3 what should the settings of your 2d convolution be that results in the following mappings (first answer given to you)*\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=10, h=8, w=8) : (out_channels=10, kernel_size=(3, 3), padding=(0, 0))\n",
        "* (c=3, h=10, w=10) ⇒ (c=22, h=10, w=10) : **Your answer in bold here**\n",
        "* (c=3, h=10, w=10) ⇒ (c=65, h=12, w=12) : **Your answer in bold here**\n",
        "* (c=3, h=10, w=10) ⇒ (c=7, h=20, w=20) : **Your answer in bold here**\n",
        "\n",
        "*Using a Kernel size of 5×5:*)\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=10, h=8, w=8) : (out_channels=10, kernel_size=(5, 5), padding=(1, 1))\n",
        "* (c=3, h=10, w=10) ⇒ (c=100, h=10, w=10) : **Your answer in bold here**\n",
        "* (c=3, h=10, w=10) ⇒ (c=23, h=12, w=12) : **Your answer in bold here**\n",
        "* (c=3, h=10, w=10) ⇒ (c=5, h=24, w=24) : **Your answer in bold here**\n",
        "\n",
        "*Using Kernel size of 5×3:*\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=10, h=8, w=8) : **Your answer in bold here**\n",
        "* (c=3, h=10, w=10) ⇒ (c=100, h=10, w=10) : **Your answer in bold here**\n",
        "* (c=3, h=10, w=10) ⇒ (c=23, h=12, w=12) : **Your answer in bold here**\n",
        "* (c=3, h=10, w=10) ⇒ (c=5, h=24, w=24) : **Your answer in bold here**\n",
        "\n",
        "*Determine the kernel that requires the smallest padding size to make the following mappings possible:*\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=10, h=9, w=7) : **Your answer in bold here**\n",
        "* (c=3, h=10, w=10) ⇒ (c=22, h=10, w=10) : **Your answer in bold here**\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "* Answer all the questions above \n",
        "\n",
        "**DONE:**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XXfG3wClh8an",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "# Write some test code for checking the answers for these problems (example shown in the video)\n"
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}